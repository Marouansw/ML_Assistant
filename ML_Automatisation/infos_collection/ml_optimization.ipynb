{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fb585fc2",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419b7bb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json \n",
    "from langchain_core.prompts import PromptTemplate\n",
    "import csv\n",
    "import os\n",
    "import re\n",
    "from langchain_ollama.llms import OllamaLLM\n",
    "import logging\n",
    "import sys\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.memory import ConversationBufferWindowMemory,ConversationBufferMemory\n",
    "from langchain_core.messages import SystemMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "logger.info(\"message\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4067c0",
   "metadata": {},
   "source": [
    "### LLM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087612aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "llm = OllamaLLM(model='mistral:7b')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645cedaa",
   "metadata": {},
   "source": [
    "### Global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3216698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_df = pd.read_csv(r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\ML_Automatisation\\param.csv\")\n",
    "\n",
    "users_state = r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\ML_Automatisation\\users_state.csv\"\n",
    "users_state_pred = r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\ML_Automatisation\\users_state_pred.csv\"\n",
    "users_state_seg = r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\ML_Automatisation\\users_state_seg.csv\"\n",
    "users_state_mon = r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\ML_Automatisation\\users_state_mon.csv\"\n",
    "users_state_vis = r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\ML_Automatisation\\users_state_vis.csv\"\n",
    "\n",
    "csv_dict = {\n",
    "    \"prediction\": users_state_pred,\n",
    "    \"forecasting\": users_state_pred,\n",
    "    \"segmentation\": users_state_seg,\n",
    "    \"monitoring\": users_state_mon,\n",
    "    \"visualisation\": users_state_vis,\n",
    "    \"processing\": users_state_vis,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "memory_dict = {}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a49d08",
   "metadata": {},
   "source": [
    "### Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e862c200",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_validity (intent,name_project:str=\"null\",name_table:str=\"null\",feature_to_predict:str=\"null\",clusters:str=\"null\",description:str=\"null\") :\n",
    "    \"checks the validity of the provided informations\"\n",
    "    the_name_project = name_project.lower()\n",
    "    pd_status = \"valid\" if the_name_project in param_df[\"project_dir\"].values else \"invalid\"\n",
    "    \n",
    "    the_name_table = name_table.lower()\n",
    "    dsp_status = \"valid\" if the_name_table in param_df[\"dataset_path\"].values else \"invalid\"\n",
    "    \n",
    "    the_feature_to_predict = feature_to_predict.lower()\n",
    "    ftp_status = \"valid\" if the_feature_to_predict in param_df[\"feature_to_predict\"].values else \"invalid\"\n",
    "    \n",
    "    if intent == \"prediction\" or intent ==\"forecasting\":\n",
    "        return f'{{\"project_dir\" : \"{the_name_project}\", \\n \"pd_status\": \"{pd_status}\",\\n \"dataset_path\" : \"{the_name_table}\", \\n \"dsp_status\":\"{dsp_status}\", \\n \"feature_to_predict\": \"{the_feature_to_predict}\", \\n \"ftp_status\":\"{ftp_status}\"}}'\n",
    "    elif intent == \"monitoring\" :\n",
    "        return f'{{\"project_dir\" : \"{the_name_project}\", \\n \"pd_status\": \"{pd_status}\",\\n \"dataset_path\" : \"{the_name_table}\", \\n \"dsp_status\":\"{dsp_status}\"}}'\n",
    "    elif intent == \"segmentation\":\n",
    "        return f'{{\"project_dir\" : \"{the_name_project}\", \\n \"pd_status\": \"{pd_status}\",\\n \"dataset_path\" : \"{the_name_table}\", \\n \"dsp_status\":\"{dsp_status}\", \\n \"clusters\":\"{clusters}\"}}'\n",
    "\n",
    "    elif intent == \"visualisation\" or intent==\"processing\":\n",
    "        return f'{{\"project_dir\" : \"{the_name_project}\", \\n \"pd_status\": \"{pd_status}\",\\n \"dataset_path\" : \"{the_name_table}\", \\n \"dsp_status\":\"{dsp_status}\", \\n \"description\":\"{description}\"}}'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0263b6f",
   "metadata": {},
   "source": [
    "### User history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad0bbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_state(user_id,intent) -> tuple:\n",
    "    \"\"\"\n",
    "    Returns a tuple (previous_state, current_state) for a given user_id.\n",
    "    If no current_state row exists, it creates one with empty fields and returns it.\n",
    "    \"\"\"\n",
    "    previous_state = None\n",
    "    current_state = None\n",
    "    rows = []\n",
    "    csv_file = csv_dict[intent]\n",
    "    \n",
    "    with open(csv_file, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        fieldnames = reader.fieldnames\n",
    "        rows = list(reader)\n",
    "\n",
    "        for row in rows:\n",
    "            if row['user_id'] == user_id:\n",
    "                if row.get(\"status_action\") == \"previous_state\":\n",
    "                    previous_state = dict(row)\n",
    "                elif row.get(\"status_action\") == \"current_state\" or row.get(\"status_action\") == \"\":\n",
    "                    current_state = dict(row)\n",
    "\n",
    "    # If current_state is not found, create it with empty fields and save\n",
    "    if not current_state:\n",
    "        current_state = {field: \"\" for field in fieldnames}\n",
    "        current_state[\"user_id\"] = user_id\n",
    "        current_state[\"status_action\"] = \"current_state\"\n",
    "        current_state[\"status\"] = \"ongoing\"\n",
    "        current_state[\"type_action\"] = \"\"\n",
    "\n",
    "        rows.append(current_state)\n",
    "\n",
    "        # Save the updated rows with the new current_state\n",
    "        with open(csv_file, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "\n",
    "    return previous_state, current_state\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf2e0da8",
   "metadata": {},
   "source": [
    "### Parse JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "22c7fd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def clean_and_parse(json_str):\n",
    "    try:\n",
    "        # Find all JSON-like blocks (starts with { and ends with })\n",
    "        matches = re.findall(r'\\{.*?\\}', json_str.strip(), re.DOTALL)\n",
    "\n",
    "        if not matches:\n",
    "            raise ValueError(\"No valid JSON object found.\")\n",
    "\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Remove trailing commas (common LLM mistake)\n",
    "                cleaned = re.sub(r',(\\s*[}\\]])', r'\\1', match)\n",
    "                return json.loads(cleaned)\n",
    "            except json.JSONDecodeError:\n",
    "                continue  # Try next match if this one fails\n",
    "\n",
    "        raise ValueError(\"All extracted JSON blocks failed to parse.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Please reformulate your prompt : {e}\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a3515d4",
   "metadata": {},
   "source": [
    "### New State (replace valid fields from message with previous user state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2ff31b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_user_state(user_row, infos_agent,intent):\n",
    "    \n",
    "    \"\"\"\n",
    "    Updates user_row dict with values from validate_data dict for prediction intent.\n",
    "    - For \"dsp_status\", \"pd_status\", \"ftp_status\":\n",
    "        - If status is \"valid\", update both the status and its related value in user_row from validate_data.\n",
    "        - If status is \"invalid\", leave both fields unchanged.\n",
    "    - Leave other fields unchanged.\n",
    "    Returns the updated user_row as a valid JSON string.\n",
    "    \"\"\"\n",
    "\n",
    "    # Make a copy to avoid mutating the original\n",
    "    validate_data = clean_and_parse(infos_agent)\n",
    "    updated_row = user_row.copy() \n",
    "    # Update dataset_path and dsp_status\n",
    "    if \"dsp_status\" in validate_data and validate_data[\"dsp_status\"] == \"valid\":\n",
    "        updated_row[\"dsp_status\"] = \"valid\"\n",
    "        if \"dataset_path\" in validate_data:\n",
    "            updated_row[\"dataset_path\"] = validate_data[\"dataset_path\"]\n",
    "\n",
    "    # Update project_dir and pd_status\n",
    "    if \"pd_status\" in validate_data and validate_data[\"pd_status\"] == \"valid\":\n",
    "        updated_row[\"pd_status\"] = \"valid\"\n",
    "        if \"project_dir\" in validate_data:\n",
    "            updated_row[\"project_dir\"] = validate_data[\"project_dir\"]\n",
    "\n",
    "    # Update feature_to_predict and ftp_status\n",
    "    if intent in [\"prediction\",\"forecasting\"] :\n",
    "        if \"ftp_status\" in validate_data and validate_data[\"ftp_status\"] == \"valid\":\n",
    "            updated_row[\"ftp_status\"] = \"valid\"\n",
    "            if \"feature_to_predict\" in validate_data:\n",
    "                updated_row[\"feature_to_predict\"] = validate_data[\"feature_to_predict\"]\n",
    "    if intent == \"segmentation\" :\n",
    "        clusters_value = validate_data.get(\"clusters\")\n",
    "        if clusters_value not in [None, \"not found\", \"null\"]:\n",
    "            updated_row[\"clusters\"] = clusters_value # This will be False for None, \"\", 0, [], etc.\n",
    "            \n",
    "    if intent in [\"visualisation\", \"processing\"]:\n",
    "        desc_value = validate_data.get(\"description\")\n",
    "        current_desc = updated_row.get(\"description\", \"\").strip()\n",
    "            # Add a separator if there's already something written\n",
    "        if current_desc:\n",
    "            updated_row[\"description\"] = current_desc + \" | \" + desc_value.strip()\n",
    "        else:\n",
    "            updated_row[\"description\"] = desc_value.strip()\n",
    "\n",
    "    return updated_row\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c75eb",
   "metadata": {},
   "source": [
    "### Agent : Prediction & Tendance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b0b222fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def infos_validation_pred(intent,query,previous_state) :\n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant for a prediction task. Your job has two parts:\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1 – Extract three specific fields from the user's input**:  \n",
    "These fields are:\n",
    "- \"project_dir\" (project directory name)  \n",
    "- \"dataset\" (CSV or dataset name)  \n",
    "- \"feature_to_predict\" (the prediction target)  \n",
    "\n",
    "For **each field**, follow this exact logic:\n",
    "\n",
    "1. If the user **explicitly provides a value** for this field → use that value.  \n",
    "2. Else if the user **explicitly asks to keep or reuse the previous value** for this field (e.g., \"keep the same dataset\", \"use previous project_dir\") → set it to `\"previous\"`.  \n",
    "3. Else → set it to `\"not found\"`.\n",
    "\n",
    "⚠️ You must **evaluate each field separately**.  \n",
    "⚠️ Do **NOT** assume or guess that a field should be `\"previous\"` unless the user says so **clearly and specifically for that exact field**.  \n",
    "⚠️ If the user mentions only one field, all other fields must be set to `\"not found\"` unless also mentioned.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2 – Respond ONLY with JSON, no extra text**:  \n",
    "Format:  \n",
    "{{\n",
    "  \"project_dir\": \"<value>\" or \"previous\" or \"not found\",\n",
    "  \"dataset\": \"<value>\" or \"previous\" or \"not found\",\n",
    "  \"feature_to_predict\": \"<value>\" or \"previous\" or \"not found\"\n",
    "}}\n",
    "\n",
    "User input: {input}\n",
    "\"\"\")\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "    response = llm.invoke(prompt.format(input=query))\n",
    "    print(\"LLM reponse \",response)\n",
    "    clean_reponse = clean_and_parse(response)\n",
    "    \n",
    "    if not clean_reponse:\n",
    "        return None\n",
    "    if previous_state : \n",
    "        if clean_reponse[\"project_dir\"] == \"previous\" :\n",
    "            clean_reponse[\"project_dir\"] = previous_state[\"project_dir\"]\n",
    "        if clean_reponse[\"dataset\"] == \"previous\" :\n",
    "            clean_reponse[\"dataset\"] = previous_state[\"dataset_path\"]\n",
    "        if clean_reponse[\"feature_to_predict\"] == \"previous\" :\n",
    "            clean_reponse[\"feature_to_predict\"] = previous_state[\"feature_to_predict\"]    \n",
    "        \n",
    "    print(\"Cleaned response:\", clean_reponse)\n",
    "    infos_validity = check_validity(intent=intent,name_project=clean_reponse[\"project_dir\"],name_table=clean_reponse[\"dataset\"],feature_to_predict=clean_reponse[\"feature_to_predict\"])\n",
    "    return(infos_validity)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a6fc48",
   "metadata": {},
   "source": [
    "### Agent : Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4b0bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_validation_seg(intent,query,previous_state) :\n",
    "    \n",
    "  prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant for a segmentation task. Your job has two parts:\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1 – Extract three specific fields from the user's input**:  \n",
    "These fields are:\n",
    "- \"project_dir\" (project directory name)  \n",
    "- \"dataset\" (CSV or dataset name)  \n",
    "- \"Clusters\" (the clusters number)  \n",
    "\n",
    "For **each field**, follow this exact logic:\n",
    "\n",
    "1. If the user **explicitly provides a value** for this field → use that value.  \n",
    "2. Else if the user **explicitly asks to keep or reuse the previous value** for this field (e.g., \"keep the same dataset\", \"use previous project_dir\") → set it to `\"previous\"`.  \n",
    "3. Else → set it to `\"not found\"`.\n",
    "\n",
    "⚠️ You must **evaluate each field separately**.  \n",
    "⚠️ Do **NOT** assume or guess that a field should be `\"previous\"` unless the user says so **clearly and specifically for that exact field**.  \n",
    "⚠️ If the user mentions only one field, all other fields must be set to `\"not found\"` unless also mentioned.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2 – Respond ONLY with JSON, no extra text**:  \n",
    "Format:  \n",
    "{{\n",
    "  \"project_dir\": \"<value>\" or \"previous\" or \"not found\",\n",
    "  \"dataset\": \"<value>\" or \"previous\" or \"not found\",\n",
    "  \"clusters\": \"<value>\" or \"previous\" or \"not found\"\n",
    "}}\n",
    "\n",
    "User input: {input}\n",
    "\"\"\")\n",
    "\n",
    "  response = llm.invoke(prompt.format(input=query))\n",
    "  print(\"LLM reponse \",response)\n",
    "  clean_reponse = clean_and_parse(response)\n",
    "  if previous_state : \n",
    "        if clean_reponse[\"project_dir\"] == \"previous\" :\n",
    "            clean_reponse[\"project_dir\"] = previous_state[\"project_dir\"]\n",
    "        if clean_reponse[\"dataset\"] == \"previous\" :\n",
    "            clean_reponse[\"dataset\"] = previous_state[\"dataset_path\"]\n",
    "        if clean_reponse[\"clusters\"] == \"previous\" :\n",
    "            clean_reponse[\"clusters\"] = previous_state[\"clusters\"]    \n",
    "  infos_validity = check_validity(intent,name_project=clean_reponse[\"project_dir\"],name_table=clean_reponse[\"dataset\"],clusters=clean_reponse[\"clusters\"])\n",
    "  return(infos_validity)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45d70163",
   "metadata": {},
   "source": [
    "### Agent : monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "411aa8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def infos_validation_mon(intent,query,previous_state) :\n",
    "    \n",
    "    prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a helpful assistant for a monitoring task. Your job has two parts:\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1 – Extract two specific fields from the user's input**:  \n",
    "These fields are:\n",
    "- \"project_dir\" (project directory name)  \n",
    "- \"dataset\" (CSV or dataset name)  \n",
    "\n",
    "For **each field**, follow this exact logic:\n",
    "\n",
    "1. If the user **explicitly provides a value** for this field → use that value.  \n",
    "2. Else if the user **explicitly asks to keep or reuse the previous value** for this field (e.g., \"keep the same dataset\", \"use previous project_dir\") → set it to `\"previous\"`.  \n",
    "3. Else → set it to `\"not found\"`.\n",
    "\n",
    "⚠️ You must **evaluate each field separately**.  \n",
    "⚠️ Do **NOT** assume or guess that a field should be `\"previous\"` unless the user says so **clearly and specifically for that exact field**.  \n",
    "⚠️ If the user mentions only one field, all other fields must be set to `\"not found\"` unless also mentioned.\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2 – Respond ONLY with JSON, no extra text**:  \n",
    "Format:  \n",
    "{{\n",
    "  \"project_dir\": \"<value>\" or \"previous\" or \"not found\",\n",
    "  \"dataset\": \"<value>\" or \"previous\" or \"not found\"\n",
    "}}\n",
    "\n",
    "User input: {input}\n",
    "\"\"\")\n",
    "\n",
    "    response = llm.invoke(prompt.format(input=query))\n",
    "    print(\"LLM reponse \",response)\n",
    "    clean_reponse = clean_and_parse(response)\n",
    "    if previous_state : \n",
    "        if clean_reponse[\"project_dir\"] == \"previous\" :\n",
    "            clean_reponse[\"project_dir\"] = previous_state[\"project_dir\"]\n",
    "        if clean_reponse[\"dataset\"] == \"previous\" :\n",
    "            clean_reponse[\"dataset\"] = previous_state[\"dataset_path\"]\n",
    " \n",
    "    infos_validity = check_validity(intent,name_project=clean_reponse[\"project_dir\"],name_table=clean_reponse[\"dataset\"])\n",
    "    return(infos_validity)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4840953",
   "metadata": {},
   "source": [
    "### Visualisation and Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6f665e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "def infos_validation_vis_pro(intent, query, previous_state):\n",
    "    \"\"\"\n",
    "    Extracts and validates project_dir and dataset for visualization/processing tasks.\n",
    "    \"\"\"\n",
    "    prompt = PromptTemplate.from_template(f\"\"\"\n",
    "You are a helpful assistant for a {intent} task. Your job has two parts:\n",
    "\n",
    "---\n",
    "\n",
    "**Step 1 – Extract two specific fields from the user's input**:\n",
    "These fields are:\n",
    "- \"project_dir\" (project directory name)\n",
    "- \"dataset\" (CSV or dataset name)\n",
    "\n",
    "For each field, follow exactly:\n",
    "1. If the user explicitly provides a value → use that value.\n",
    "2. Else if the user explicitly asks to keep/reuse the previous value → set it to \"previous\".\n",
    "3. Else → set it to \"not found\".\n",
    "\n",
    "⚠️ Evaluate each field separately.\n",
    "⚠️ Do NOT assume or guess \"previous\" unless explicitly stated.\n",
    "⚠️ If the user mentions only one field, set all others to \"not found\".\n",
    "\n",
    "---\n",
    "\n",
    "**Step 2 – Respond ONLY with JSON, no extra text**:\n",
    "Format:\n",
    "{{\n",
    "  \"project_dir\": \"<value>\" or \"previous\" or \"not found\",\n",
    "  \"dataset\": \"<value>\" or \"previous\" or \"not found\"\n",
    "}}\n",
    "\n",
    "User input: {query}\n",
    "\"\"\")\n",
    "\n",
    "    try:\n",
    "        response = llm.invoke(prompt.format(intent=intent,query=query))\n",
    "        logging.debug(\"LLM raw response: %s\", response)\n",
    "        \n",
    "        clean_response = clean_and_parse(response)\n",
    "\n",
    "        # Vérification des clés\n",
    "        for key in [\"project_dir\", \"dataset\"]:\n",
    "            if key not in clean_response:\n",
    "                logging.error(\"Missing key '%s' in LLM response\", key)\n",
    "                clean_response[key] = \"not found\"\n",
    "\n",
    "        # Gestion des valeurs \"previous\"\n",
    "        if previous_state:\n",
    "            if clean_response[\"project_dir\"] == \"previous\":\n",
    "                clean_response[\"project_dir\"] = previous_state.get(\"project_dir\", \"not found\")\n",
    "            if clean_response[\"dataset\"] == \"previous\":\n",
    "                clean_response[\"dataset\"] = previous_state.get(\"dataset_path\", \"not found\")\n",
    "\n",
    "        clean_response[\"description\"] = query\n",
    "\n",
    "        infos_validity = check_validity(\n",
    "            intent,\n",
    "            name_project=clean_response[\"project_dir\"],\n",
    "            name_table=clean_response[\"dataset\"],\n",
    "            description=clean_response[\"description\"]\n",
    "        )\n",
    "        return infos_validity\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.exception(\"Error during infos_validation_vis_pro execution: %s\", e)\n",
    "        return {\"error\": str(e), \"status\": \"failed\"}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a167518e",
   "metadata": {},
   "source": [
    "### Execution Agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8f2c30e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent_execution(valid_fields, intent):\n",
    "  \n",
    "    valid_intents = {\n",
    "        \"prediction\",\n",
    "        \"forecasting\",\n",
    "        \"segmentation\",\n",
    "        \"monitoring\",\n",
    "        \"visualisation\",\n",
    "        \"processing\"\n",
    "    }\n",
    "    \n",
    "    if intent in valid_intents:\n",
    "        return f\"✅ The {intent} Agent is being executed !!!\"\n",
    "    \n",
    "    return f\"❌ Unknown intent: {intent}. Execution aborted.\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee690da",
   "metadata": {},
   "source": [
    "### Diplay valid/invalid fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "682246c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def validate_data1(valid_fields1, invalid_fields):\n",
    "    \"\"\"Logs the result of a validation check on provided fields.\"\"\"\n",
    "    logger.info(\"-\" * 40)\n",
    "    logger.info(\"Validation Results:\")\n",
    "\n",
    "    if valid_fields1:\n",
    "        logger.info(\"✅ Valid fields : \")\n",
    "        max_key_len = max(len(k) for k in valid_fields1)\n",
    "        for key, value in valid_fields1.items():\n",
    "            if key == \"Description\":\n",
    "                continue\n",
    "            logger.info(f\"{key.ljust(max_key_len)} : {value}\")\n",
    "    else:\n",
    "        logger.info(\"⚠️ No valid fields provided.\")\n",
    "\n",
    "    if invalid_fields:\n",
    "        logger.warning(\"❌ Invalid fields: \\n %s\", \", \".join(invalid_fields))\n",
    "    else:\n",
    "        logger.info(\"✅ No invalid fields detected.\")\n",
    "\n",
    "    logger.info(\"-\" * 40)\n",
    "    logger.info(\"ℹ️ Awaiting missing or corrected information.\")\n",
    "\n",
    "def validate_data2(user_input, valid_fields1, intent):\n",
    "    \"\"\"\n",
    "    Validates the user's confirmation based on input.\n",
    "    Returns 'yes' / 'no' / None depending on user confirmation.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        prompt = PromptTemplate.from_template(\"\"\"\n",
    "You are a confirmation-checking assistant. Your task is to decide if the user is explicitly confirming an action.\n",
    "\n",
    "Rules:\n",
    "- Respond only with **yes** if the user clearly and explicitly confirms using words like \"yes\", \"confirm\", \"okay\", \"proceed\", or \"go ahead\".\n",
    "- If the user is still providing information, asking questions, making changes, or specifying details (e.g., project names, paths, numbers, options), respond with **no**.\n",
    "- Do not infer confirmation from intent; only explicit confirmation counts.\n",
    "- Respond with exactly \"yes\" or \"no\". Nothing else.\n",
    "\n",
    "User Input: {user_input}\n",
    "\n",
    "Examples:\n",
    "- \"I want to use 4 clusters\" → no\n",
    "- \"I want to use project_1 directory\" → no\n",
    "- \"Yes, I confirm\" → yes\n",
    "- \"Please proceed\" → yes\n",
    "- \"Use project_2\" → no\n",
    "\"\"\")\n",
    "        response = llm.invoke(prompt.format(user_input=user_input))\n",
    "        cleaned_response = response.strip().lower()\n",
    "\n",
    "        if cleaned_response == \"yes\":\n",
    "            return \"yes\"\n",
    "        else:\n",
    "            logger.info(\"-\" * 40)\n",
    "            logger.info(\"✅ All provided information is valid:\")\n",
    "            max_key_len = max(len(k) for k in valid_fields1)\n",
    "            for key, value in valid_fields1.items():\n",
    "                logger.info(f\"{key.ljust(max_key_len)} : {value}\")\n",
    "            logger.info(\"-\" * 40)\n",
    "            logger.info(f\"❓ Awaiting confirmation to execute the '{intent}' agent.\")\n",
    "            return None\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Error during confirmation prompt: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb94d4",
   "metadata": {},
   "source": [
    "### General \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "5ebdee39",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def llm_general(user_id, query):\n",
    "    if not query:\n",
    "        return \"⚠️ No query provided.\"\n",
    "\n",
    "    try:\n",
    "        if user_id not in memory_dict:\n",
    "            memory_dict[user_id] = ConversationBufferMemory(\n",
    "                memory_key=\"chat_history\",\n",
    "                return_messages=True,\n",
    "                input_key=\"text\"\n",
    "            )\n",
    "        memory = memory_dict[user_id]\n",
    "\n",
    "        prompt = ChatPromptTemplate(\n",
    "            [\n",
    "                SystemMessage(content=\"\"\"You are an AI expert that only handles AI-related questions, and also assist users about task executions for our machine learning automation purpose, in the following categories:\n",
    "\n",
    "1. Prediction/Forecasting Task\n",
    "2. Segmentation Task\n",
    "3. Monitoring Task\n",
    "4. Data Processing/Visualization Task\n",
    "\n",
    "Instructions:\n",
    "- If the user input is not related to AI or the tasks above, respond with:\n",
    "  **\"Sorry, we don't handle such type of question, please enter a question related to AI.\"**\n",
    "\n",
    "- If the user wants to perform a task, assist them with the required information:\n",
    "    • For **Prediction/Forecasting**: requires `project directory name`, `dataset name`, and `target feature to predict`.\n",
    "    • For **Segmentation**: requires `project directory name`, `dataset name`, and `number of clusters`.\n",
    "    • For **Monitoring**: requires `project directory name` and `dataset name`.\n",
    "    • For **Data Processing/Visualization**: requires `project directory name`, `dataset name`, and a clear `description of what the agent should do`.\n",
    "\n",
    "-if the user asks a general question related to AI:\n",
    "    • 1. Be **Clear and Concise**: Avoid unnecessary jargon, and break down complex concepts into easy-to-understand explanations. Aim for clarity while maintaining technical accuracy.\n",
    "    • 2. Provide **Examples**: Use practical examples to illustrate concepts, making them relatable and easier to grasp.\n",
    "\n",
    "\n",
    "User Input: {user_input}\n",
    "\n",
    "\"\"\"),\n",
    "                MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "                HumanMessagePromptTemplate.from_template(\"{text}\"),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        general_out = LLMChain(llm=llm, prompt=prompt, memory=memory)\n",
    "        response = general_out.invoke({\"text\": query})\n",
    "\n",
    "        return response.get(\"text\", \"⚠️ No valid response from LLM.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        # Logging en prod préférable à un print\n",
    "        print(f\"❌ Error in llm_general: {e}\")\n",
    "        return \"⚠️ An error occurred while processing your request.\"\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bf5809f",
   "metadata": {},
   "source": [
    "### Clear user history (for switched/complete path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "037fd7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_current_state(user_id):\n",
    "    csv_path = users_state\n",
    "    rows = []\n",
    "    with open(csv_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "        reader = csv.DictReader(file)\n",
    "        fieldnames = reader.fieldnames\n",
    "        for row in reader:\n",
    "            if row['user_id'] == str(user_id) :\n",
    "                if row['status_action'] != \"previous_state\" :\n",
    "                    for key in row:\n",
    "                        if key != \"user_id\":\n",
    "                            row[key] = \"\"\n",
    "                \n",
    "            rows.append(row)\n",
    "    with open(csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "        writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)\n",
    "    print(f\"Cleared user state for user_id={user_id}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702b6639",
   "metadata": {},
   "source": [
    "### Insert row "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69281bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "def update_row(user_input, update_dict, intent):\n",
    "    \"\"\"\n",
    "    Updates a user's row in the CSV based on intent and update_dict.\n",
    "    Keeps previous state if current is not validated; removes it if validated.\n",
    "    Returns valid fields and a list of invalid fields.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        csv_path = csv_dict[intent]\n",
    "        user_id = str(update_dict.get(\"user_id\"))\n",
    "        rows = []\n",
    "        invalid_fields = []\n",
    "        validated_fields = {}\n",
    "        updated = False\n",
    "        previous_state = None\n",
    "        row_to_update = None\n",
    "        response = None  \n",
    "\n",
    "        with open(csv_path, mode='r', newline='', encoding='utf-8') as file:\n",
    "            reader = csv.DictReader(file)\n",
    "            fieldnames = reader.fieldnames\n",
    "\n",
    "            for row in reader:\n",
    "                if row['user_id'] == user_id:\n",
    "                    if row['status_action'] != \"previous_state\":\n",
    "                        for key, value in update_dict.items():\n",
    "                            if key in row:\n",
    "                                row[key] = value\n",
    "\n",
    "                            if key == \"dsp_status\":\n",
    "                                if value != \"valid\":\n",
    "                                    invalid_fields.append(\"Dataset path\")\n",
    "                                else:\n",
    "                                    validated_fields[\"Dataset path\"] = row[\"dataset_path\"]\n",
    "\n",
    "                            if key == \"pd_status\":\n",
    "                                if value != \"valid\":\n",
    "                                    invalid_fields.append(\"Project directory\")\n",
    "                                else:\n",
    "                                    validated_fields[\"Project directory\"] = row[\"project_dir\"]\n",
    "\n",
    "                            if intent == \"segmentation\":\n",
    "                                if key == \"clusters\" and not value:\n",
    "                                    invalid_fields.append(\"Clusters\")\n",
    "                                elif key == \"clusters\" and value:\n",
    "                                    validated_fields[\"Clusters\"] = value\n",
    "\n",
    "                            if intent in (\"prediction\", \"forecasting\"):\n",
    "                                if key == \"ftp_status\":\n",
    "                                    if value != \"valid\":\n",
    "                                        invalid_fields.append(\"Feature to predict\")\n",
    "                                    else:\n",
    "                                        validated_fields[\"Feature to predict\"] = row[\"feature_to_predict\"]\n",
    "\n",
    "                            if intent in (\"visualisation\", \"processing\"):\n",
    "                                if key == \"description\":\n",
    "                                    validated_fields[\"Description\"] = value\n",
    "                                    desc = value\n",
    "\n",
    "                        row[\"type_action\"] = intent\n",
    "\n",
    "                        if invalid_fields:\n",
    "                            validate_data1(validated_fields, invalid_fields)\n",
    "                        else:\n",
    "                            if intent in (\"visualisation\", \"processing\"):\n",
    "                                prompt = PromptTemplate.from_template(\"\"\"You are given an unstructured string containing information about a data {intent} task. This string includes the dataset name, the project directory, and a description (details) of the task.\n",
    "\n",
    "Your job is to extract and rephrase the description of the task into a clear, complete sentence suitable for an automated agent to execute.\n",
    "\n",
    "The structured sentence should follow this exact format:\n",
    "\n",
    "\"the task is to `<task_description>`.\"\n",
    "\n",
    "### Input:\n",
    "{desc}\n",
    "\n",
    "### Output:\n",
    "A single clear sentence following the format above.\"\"\")\n",
    "\n",
    "                                summary = llm.invoke(prompt.format(intent=intent, desc=validated_fields[\"Description\"]))\n",
    "                                logger.info(f\"Summary : {summary}\")\n",
    "                                validated_fields[\"Description\"] = summary\n",
    "                                row[\"description\"] = summary\n",
    "\n",
    "                            response = validate_data2(user_input, validated_fields, intent)\n",
    "\n",
    "                        if response:\n",
    "                            if response == \"yes\":\n",
    "                                result = agent_execution(validated_fields, intent)\n",
    "                                logger.info(f\"Agent Output: {result}\")\n",
    "                                row[\"status\"] = \"validated\"\n",
    "                            else:\n",
    "                                row[\"status\"] = \"ongoing\"\n",
    "                        else:\n",
    "                            row[\"status\"] = \"ongoing\"\n",
    "\n",
    "                        row[\"status_action\"] = \"previous_state\" if row[\"status\"] == \"validated\" else \"current_state\"\n",
    "                        updated = True\n",
    "                        row_to_update = row\n",
    "\n",
    "                    elif row['status_action'] == \"previous_state\":\n",
    "                        previous_state = row\n",
    "                else:\n",
    "                    rows.append(row)\n",
    "\n",
    "        if not updated:\n",
    "            raise ValueError(\"No editable row found for this user_id.\")\n",
    "\n",
    "        if row_to_update:\n",
    "            if row_to_update[\"status\"] == \"validated\":\n",
    "                rows.append(row_to_update)\n",
    "            else:\n",
    "                if previous_state:\n",
    "                    rows.append(previous_state)\n",
    "                rows.append(row_to_update)\n",
    "\n",
    "        with open(csv_path, mode='w', newline='', encoding='utf-8') as file:\n",
    "            writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "            writer.writeheader()\n",
    "            writer.writerows(rows)\n",
    "\n",
    "        return validated_fields, invalid_fields\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"❌ Failed to update row for user_id={update_dict.get('user_id')}: {e}\")\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0a8391",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6111b2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(message)s\",\n",
    "    handlers=[logging.StreamHandler(sys.stdout)]\n",
    ")\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "validation_funcs = {\n",
    "    \"segmentation\": infos_validation_seg,\n",
    "    \"prediction\": infos_validation_pred,\n",
    "    \"forecasting\": infos_validation_pred,\n",
    "    \"monitoring\": infos_validation_mon,\n",
    "    \"visualisation\": infos_validation_vis_pro,\n",
    "    \"processing\": infos_validation_vis_pro,\n",
    "}\n",
    "\n",
    "\n",
    "def agent_manager1(user_id, intent, user_input):\n",
    "    try:\n",
    "        if intent != \"general\":\n",
    "            previous_state, current_state = get_state(user_id, intent)\n",
    "            type_action = current_state.get(\"type_action\", None)\n",
    "            logger.info(f\"Current: {current_state}, Intent: {intent}, Input: {user_input}\")\n",
    "\n",
    "            if intent in validation_funcs:\n",
    "                infos = validation_funcs[intent](intent, user_input, previous_state)\n",
    "                if not infos:\n",
    "                    raise ValueError(\"Validation failed.\")\n",
    "                user_state = new_user_state(current_state, infos, intent)\n",
    "                valid_fields, invalid_fields = update_row(user_input, user_state, intent)\n",
    "            else:\n",
    "                logger.warning(\"Intent not handled\")\n",
    "        else:\n",
    "            out = llm_general(user_id=user_id, query=user_input)\n",
    "            logger.info(out)\n",
    "\n",
    "    except Exception as e:\n",
    "        logger.exception(f\"Agent manager failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "25d5a844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current: {'user_id': '7', 'dataset_path': 'housing.csv', 'dsp_status': 'valid', 'project_dir': 'project_1', 'pd_status': 'valid', 'description': ' \"The task is to visualize data from the \\'housing.csv\\' dataset, using either \\'table_1.csv\\' or the previously used table.\"', 'type_action': 'visualisation', 'status_action': 'current_state', 'status': 'ongoing'}, Intent: visualisation, Input: i want use table 'housing.csv'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "LLM reponse   {\n",
      "  \"project_dir\": \"not found\",\n",
      "  \"dataset\": \"housing.csv\"\n",
      "}\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "Summary :  \"The task is to visualize data from the 'housing.csv' dataset using either 'table_1.csv' or the previously used table.\"\n",
      "HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n",
      "----------------------------------------\n",
      "✅ All provided information is valid:\n",
      "Dataset path      : housing.csv\n",
      "Project directory : project_1\n",
      "Description       :  \"The task is to visualize data from the 'housing.csv' dataset using either 'table_1.csv' or the previously used table.\"\n",
      "----------------------------------------\n",
      "❓ Awaiting confirmation to execute the 'visualisation' agent.\n"
     ]
    }
   ],
   "source": [
    "user_id = \"7\" \n",
    "user_input = \"i want use table 'housing.csv'\"\n",
    "intent = \"visualisation\"  \n",
    "agent_manager1(user_id, intent, user_input) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.12.0)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
