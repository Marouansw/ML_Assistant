{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\donnee_use_case_structuré.pdf\")\n",
    "data = loader.load()\n",
    "print(len(data))\n",
    "print(type(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_ollama\n",
      "  Obtaining dependency information for langchain_ollama from https://files.pythonhosted.org/packages/44/a1/a7dbdc39365f2f148a91724d8d52c0028cafe7dd6f0257462bc187bc4643/langchain_ollama-0.3.0-py3-none-any.whl.metadata\n",
      "  Downloading langchain_ollama-0.3.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting ollama<1,>=0.4.4 (from langchain_ollama)\n",
      "  Obtaining dependency information for ollama<1,>=0.4.4 from https://files.pythonhosted.org/packages/31/83/c3ffac86906c10184c88c2e916460806b072a2cfe34cdcaf3a0c0e836d39/ollama-0.4.7-py3-none-any.whl.metadata\n",
      "  Using cached ollama-0.4.7-py3-none-any.whl.metadata (4.7 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain_ollama) (0.3.48)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_ollama) (2.10.6)\n",
      "Requirement already satisfied: httpx<0.29,>=0.27 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from ollama<1,>=0.4.4->langchain_ollama) (0.28.1)\n",
      "Requirement already satisfied: anyio in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (4.9.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from httpcore==1.*->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_ollama) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\lenovo\\desktop\\ml_rag\\venv\\lib\\site-packages (from anyio->httpx<0.29,>=0.27->ollama<1,>=0.4.4->langchain_ollama) (1.3.1)\n",
      "Downloading langchain_ollama-0.3.0-py3-none-any.whl (20 kB)\n",
      "Downloading ollama-0.4.7-py3-none-any.whl (13 kB)\n",
      "Installing collected packages: ollama, langchain_ollama\n",
      "Successfully installed langchain_ollama-0.3.0 ollama-0.4.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_ollama\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'utilisation des clients\n",
      "Univers : Lignes\n",
      "Variable : LIGNE_ID\n",
      "Description : Identifiant de la ligne (numéro de téléphone)\n",
      "Utilisé pour : La segmentation (Oui)\n",
      "Churn : Oui\n",
      "Nb : 1\n",
      "Univers : Lignes\n",
      "Variable : LIGNE_TYP\n",
      "Description : Type de ligne (prépayé ou postpayé)\n",
      "Utilisé pour : La segmentation (Oui)\n",
      "Churn : Non\n",
      "Nb : 1\n",
      "Univers : Lignes\n",
      "Variable : LIGNE_CUST_ANC\n",
      "Description : Ancienneté de la ligne en jours (date courante - date d'activation de la ligne)\n",
      "Utilisé pour : La segmentation (Oui)\n",
      "Churn : Oui\n",
      "Nb : 1\n",
      "Univers : Lignes\n",
      "Variable : LIGNE_DATE_ACT\n",
      "Description : Date d'activation de la ligne\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "print((chunks[0].page_content))\n",
    "print(type(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.vectorstores.faiss.FAISS'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "os.environ[\"NOMIC_API_KEY\"] = \"nk-uC7cI5olWsQ8GFL5d_y54N5zpNlx9vH86SgOieRzBWA\"\n",
    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=chunks, embedding=embeddings)\n",
    "print(type(vector_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------QUERY--------------\n",
    "query = \"Quel sont les variables pour predire le churn et non pas la segmentation?\"\n",
    "\n",
    "# retrieved_docs = retriever.invoke(query)\n",
    "retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "prompt = f\"Contexte:\\n{context}\\n\\nQuestion: {query}\\rReponse:\"\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: D'après les informations fournies, les variables qui peuvent être utilisées pour prédire le churn (c'est-à-dire prédiser si un client va abandonner son abonnement ou non) plutôt que la segmentation sont :\n",
      "\n",
      "1. REV_INTL_AMT_BASE_4 : Revenu généré par les appels internationaux de type voix lors du mois M-4\n",
      "2. REV_INTL_AMT_BASE_5 : Revenu généré par les appels internationaux de type voix lors du mois M-5\n",
      "3. REV_INTL_AMT_BASE_6 : Revenu généré par les appels internationaux de type voix lors du mois M-6\n",
      "4. _2424_USE_FLG_BASE_4 : Indicateur d'utilisation du 2424 lors du mois M-4\n",
      "5. _2424_USE_FLG_BASE_5 : Indicateur d'utilisation du 2424 lors du mois M-5\n",
      "6. _2424_USE_FLG_BASE_6 : Indicateur d'utilisation du 2424 lors du mois M-6\n",
      "7. LIGNE_DATE_RES : Date de résiliation de la ligne\n",
      "8. LIGNE_PLAFOND_AMT : Montant de plafonnement\n",
      "9. OB_CALL_OPRT_MEDITEL_CNT_BASE_4 : Nombre d'appels vers l'opérateur MEDITEL lors du mois M-4\n",
      "10. OB_CALL_OPRT_MEDITEL_CNT_BASE_5 : Nombre d'appels vers l'opérateur MEDITEL lors du mois M-5\n",
      "11. OB_CALL_OPRT_MEDITEL_CNT_BASE_6 : Nombre d'appels vers l'opérateur MEDITEL lors du mois M-6\n",
      "12. CONS_USE_FLG_BASE_4 : Indicateur d'utilisation des services de consommation lors du mois M-4\n",
      "13. CONS_USE_FLG_BASE_5 : Indicateur d'utilisation des services de consommation lors du mois M-5\n",
      "14. CONS_USE_FLG_BASE_6 : Indicateur d'utilisation des services de consommation lors du mois M-6\n",
      "15. TOT_RECHARGE_HBONUS_AMT_BASE_5 : Montant total des recharges hors bonus mois M-5\n",
      "16. TOT_RECHARGE_HBONUS_AMT_BASE_6 : Montant total des recharges hors bonus mois M-6\n",
      "17. TOT_RECHARGE_BONUS_CNT_BASE_1 : Nombre total des recharges  bonus mois M-1\n",
      "18. IB_CALL_OPRT_IAM_FIX_DUR_BASE_2 : Durée des appels provenant de l'opérateur IAM fixe lors du mois M-2\n",
      "19. IB_CALL_OPRT_IAM_FIX_DUR_BASE_3 : Durée des appels provenant de l'opérateur IAM fixe lors du mois M-3\n",
      "20. IB_CALL_OPRT_IAM_FIX_DUR_BASE_4 : Durée des appels provenant de l'opérateur IAM fixe lors du mois M-4\n",
      "\n",
      "Ces variables peuvent être utilisées pour prédire le churn en fonction des tendances et des comportements des clients, tels que :\n",
      "\n",
      "* Le revenu généré par les appels internationaux\n",
      "* L'utilisation du 2424\n",
      "* La résiliation de la ligne\n",
      "* Le montant de plafonnement\n",
      "* Le nombre d'appels vers l'opérateur MEDITEL\n",
      "* L'utilisation des services de consommation\n",
      "* Les recharges et les bonus\n",
      "* Les durées des appels provenant de l'opérateur IAM\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm=OllamaLLM(model='llama3.2:latest')\n",
    "response = llm.invoke(prompt)\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- WE HAVE TO PAY TO USE OPENAI --------------------\n",
    "\n",
    "# os.environ['OPENAI_API_KEY']='Your_openai_ApiKey'\n",
    "# from langchain_openai import OpenAI\n",
    "# llm3 = OpenAI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
