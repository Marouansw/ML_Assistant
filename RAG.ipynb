{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LOADING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "\n",
    "loader = PyPDFLoader(r\"C:\\Users\\LENOVO\\Desktop\\ML_RAG\\donnee_use_case_structuré.pdf\")\n",
    "data = loader.load()\n",
    "print(len(data))\n",
    "print(type(data))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLIT THE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Données d'utilisation des clients\n",
      "Univers : Lignes\n",
      "Description : Identifiant de la ligne (numéro de téléphone)\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Oui\n",
      "Univers : Lignes\n",
      "Description : Type de ligne (prépayé ou postpayé)\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Univers : Lignes\n",
      "Description : Ancienneté de la ligne en jours (date courante - date d'activation de la ligne)\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Oui\n",
      "Univers : Lignes\n",
      "Description : Date d'activation de la ligne\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Oui\n",
      "Univers : Lignes\n",
      "Description : Date de résiliation de la ligne\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=2000,\n",
    "    chunk_overlap=200\n",
    ")\n",
    "chunks = text_splitter.split_documents(data)\n",
    "\n",
    "print((chunks[0].page_content))\n",
    "print(type(chunks))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_community.vectorstores.faiss.FAISS'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_nomic import NomicEmbeddings\n",
    "from langchain_community.vectorstores import FAISS\n",
    "import os\n",
    "\n",
    "os.environ[\"NOMIC_API_KEY\"] = \"nk-uC7cI5olWsQ8GFL5d_y54N5zpNlx9vH86SgOieRzBWA\"\n",
    "embeddings = NomicEmbeddings(model=\"nomic-embed-text-v1.5\")\n",
    "\n",
    "\n",
    "vector_store = FAISS.from_documents(documents=chunks, embedding=embeddings)\n",
    "print(type(vector_store))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------QUERY--------------\n",
    "query = \"Quel sont les variables pour predire le churn \"\n",
    "\n",
    "# retrieved_docs = retriever.invoke(query)\n",
    "retrieved_docs = vector_store.similarity_search(query, k=5)\n",
    "\n",
    "context = \"\\n\".join([doc.page_content for doc in retrieved_docs])\n",
    "prompt = f\"Contexte:\\n{context}\\n\\nQuestion: {query}\\rReponse:\"\n",
    "# ----------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisez le contexte suivant comme information utile, mais n'hésitez pas à utiliser vos propres connaissances pour améliorer la réponse.\n",
      "Si le contexte est insuffisant ou sans rapport, fiez-vous à votre compréhension pour fournir la meilleure réponse possible.\n",
      "\n",
      "Predire le Churn : Oui\n",
      "Univers : Montant\n",
      "Description : Revenu total du mois M-3\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Montant\n",
      "Description : Revenu total du mois M-4\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Montant\n",
      "Description : Revenu total du mois M-5\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Montant\n",
      "Description : Revenu total du mois M-6\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Montant\n",
      "Description : Revenu généré par les appels internationaux de type voix lors du mois M-1\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Predire le Churn : Non\n",
      "Predire le Churn : Oui\n",
      "Univers : Fidélité\n",
      "Description : Nombre total de points de fidélité utilisés lors des 6 derniers mois \n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Oui\n",
      "Univers : Facturation\n",
      "Description : Mode de paiement actuel\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Oui\n",
      "Univers : Facturation\n",
      "Description : Part de la durée des appels vocaux sortants facturés parmi la durée du facturé total durant les 6 derniers mois\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Oui\n",
      "Univers : Recharges\n",
      "Description : Nombre moyen de recharges durant les 6 derniers mois\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Univers : Recharges\n",
      "Description : Montant moyen des recharges durant les 6 derniers mois\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Predire le Churn : Non\n",
      "Univers : Montant\n",
      "Description : Revenu total de SMS nationaux envoyés vers mobiles IAM durant les 6 derniers mois\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Univers : Montant\n",
      "Description : Revenu total de SMS nationaux envoyés vers n° spéciaux durant les 6 derniers mois\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Univers : Montant\n",
      "Description : Revenu total de SMS nationaux envoyés vers autres n°  (roaming, fax) durant les 6 derniers mois\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Univers : Montant\n",
      "Description : Revenu des appels sortants réalisés le weekend\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Univers : Montant\n",
      "Description : Revenu des appels sortants réalisés le soir (20h à 8h)\n",
      "Utilisé pour effectuer la segmentation : Oui\n",
      "  Predire le Churn : Non\n",
      "Predire le Churn : Oui\n",
      "Univers : Recharges\n",
      "Description : Nombre total des recharges  bonus mois M-1\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Recharges\n",
      "Description : Nombre total des recharges  bonus mois M-2\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Recharges\n",
      "Description : Nombre total des recharges  bonus mois M-3\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Recharges\n",
      "Description : Nombre total des recharges  bonus mois M-4\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "Univers : Recharges\n",
      "Description : Nombre total des recharges  bonus mois M-5\n",
      "Utilisé pour effectuer la segmentation : Non\n",
      "  Predire le Churn : Oui\n",
      "\n",
      "Question: Quel sont les variables pour predire le churn \n",
      "\n",
      "Reponse:\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Utilisez le contexte suivant comme information utile, mais n'hésitez pas à utiliser vos propres connaissances pour améliorer la réponse.\n",
    "Si le contexte est insuffisant ou sans rapport, fiez-vous à votre compréhension pour fournir la meilleure réponse possible.\n",
    "\n",
    "{context}\n",
    "\n",
    "Question: {question}\n",
    "\n",
    "Reponse:\"\"\"\n",
    "\n",
    "custom_rag_prompt = PromptTemplate.from_template(template)\n",
    "print(custom_rag_prompt.format(context=context, question=query))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Selon les informations fournies, les variables suivantes peuvent être utilisées pour prédire le churn :\n",
      "\n",
      "1. Revenu total du mois M-3\n",
      "2. Revenu total du mois M-4\n",
      "3. Revenu total du mois M-5\n",
      "4. Revenu total du mois M-6\n",
      "5. Revenu généré par les appels internationaux de type voix lors du mois M-1\n",
      "6. Nombre total de points de fidélité utilisés lors des 6 derniers mois\n",
      "7. Mode de paiement actuel\n",
      "8. Part de la durée des appels vocaux sortants facturés parmi la durée du facturé total durant les 6 derniers mois\n",
      "9. Nombre moyen de recharges durant les 6 derniers mois\n",
      "10. Montant moyen des recharges durant les 6 derniers mois\n",
      "\n",
      "Cependant, il est important de noter que certaines variables ne sont pas utilisées pour effectuer la segmentation, mais peuvent néanmoins avoir un impact sur le churn. C'est le cas :\n",
      "\n",
      "* Revenu total de SMS nationaux envoyés vers mobiles IAM\n",
      "* Revenu total de SMS nationaux envoyés vers n° spéciaux\n",
      "* Revenu total de SMS nationaux envoyés vers autres n° (roaming, fax)\n",
      "* Revenu des appels sortants réalisés le weekend\n",
      "* Revenu des appels sortants réalisés le soir (20h à 8h)\n",
      "\n",
      "Il est possible que ces variables aient un impact sur le churn, mais elles ne sont pas utilisées pour effectuer la segmentation.\n",
      "\n",
      "Les variables qui sont les moins pertinentes pour prédire le churn sont :\n",
      "\n",
      "* Revenu total du mois M-1\n",
      "* Nombre total des recharges bonus mois M-1 à M-5\n",
      "\n",
      "C'est probablement parce que ces variables ne sont pas corrélées avec l'évolution du revenu ou de la fidélité, ce qui est essentiel pour prédire le churn.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm=OllamaLLM(model='llama3.2:latest')\n",
    "response = llm.invoke(custom_rag_prompt.format(context=context, question=query))\n",
    "print(\"Answer:\", response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------- WE HAVE TO PAY TO USE OPENAI --------------------\n",
    "\n",
    "# os.environ['OPENAI_API_KEY']='Your_openai_ApiKey'\n",
    "# from langchain_openai import OpenAI\n",
    "# llm3 = OpenAI()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
